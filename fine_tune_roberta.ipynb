{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbab4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cba7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(list_):\n",
    "    collect = set()\n",
    "    for item in list_:\n",
    "        if item not in collect:\n",
    "            collect.add(item)\n",
    "    collect = list(collect)\n",
    "    return collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9affcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.read_csv('IMDB Dataset.csv').filter(['review'])\n",
    "\n",
    "reviews = list(movie_reviews['review'])\n",
    "reviews = remove_duplicates(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36afaf38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20997bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_synopses = pd.read_csv(r'movies_metadata.csv', low_memory=False).filter(['overview'])\n",
    "\n",
    "synopses = list(movie_synopses['overview'])\n",
    "synopses = remove_duplicates(synopses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ffa77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(filter(lambda x: not pd.isna(x), reviews))\n",
    "synopses = list(filter(lambda x: not pd.isna(x), synopses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5614f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49582 44307\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews), len(synopses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e6fde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sample reviews\n",
    "reviews = reviews[:len(synopses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25360437",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 44307, 44307)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews) == len(synopses), len(reviews), len(synopses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5dc92189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88614, 44307.0, 44307, 44307)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reviews + synopses\n",
    "len(data), len(data)/2, len(synopses), len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f30d522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88614"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce no. characters to 240 -- like Twitter, & speeds up training\n",
    "data = [text[:240] for text in data]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a713cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = len(data)\n",
    "labeled_reviews = [(reviews[i][:240], 'Subjective') for i in range(len(reviews))]\n",
    "labeled_synopses = [(synopses[i][:240], 'Objective') for i in range(len(synopses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f91e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_reviews = remove_duplicates(labeled_reviews)\n",
    "labeled_synopses = remove_duplicates(labeled_synopses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "465981f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44285, 44303)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_reviews), len(labeled_synopses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "577eafc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44285, 44285)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_synopses = labeled_synopses[:len(labeled_reviews)]\n",
    "len(labeled_reviews), len(labeled_synopses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21a83f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88570"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = labeled_reviews + labeled_synopses\n",
    "len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e30aa799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88570"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = remove_duplicates(labeled_data)\n",
    "len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2050f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "43af4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dce35054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df.rename(columns={0:'Text', 1:'Labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "187af9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A woman vanishes. Her husband inquires into th...</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portrait of the popular Dutch singer André Hazes.</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prepare to meet your Messiah - they call him M...</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After losing their son, grieving parents stumb...</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fictional account of French artist Henri de To...</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text      Labels\n",
       "0  A woman vanishes. Her husband inquires into th...   Objective\n",
       "1  Portrait of the popular Dutch singer André Hazes.   Objective\n",
       "2  Prepare to meet your Messiah - they call him M...  Subjective\n",
       "3  After losing their son, grieving parents stumb...   Objective\n",
       "4  Fictional account of French artist Henri de To...   Objective"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "19a1bd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88570,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5837d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f357ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validtion, and test sets\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(df['Text'], df['Labels'], train_size = 0.8, random_state = 24)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size = 0.5, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98f26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ceb0da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cardiffnlp/twitter-roberta-base-sentiment/tokenizer_config.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/special_tokens_map.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/vocab.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/merges.txt',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/added_tokens.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/tokenizer.json')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use roberta base sentiment model\n",
    "rbs_model = f'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(rbs_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(rbs_model)\n",
    "model.save_pretrained(rbs_model)\n",
    "tokenizer.save_pretrained(rbs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e2321966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    encoded_text = tokenizer(text, \n",
    "                             padding=True, \n",
    "                             truncation=True,\n",
    "                             max_length=512,\n",
    "                             return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "\n",
    "    prediction = torch.argmax(output.logits)\n",
    "    sentiment = labels[prediction]\n",
    "\n",
    "    polarities = output[0][0].detach().numpy()\n",
    "    polarities = softmax(polarities)\n",
    "\n",
    "    polarity_scores = dict(zip(labels, polarities))\n",
    "\n",
    "    return sentiment, polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1de38ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_sentiments(text_list):\n",
    "    return [predict_sentiment(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6ad8f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'neutral', 'negative', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "texts = list(df['Text'][:5])\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    predictions = predict_multi_sentiments(texts)\n",
    "    stmnt_preds = [pred[0] for pred in predictions]\n",
    "\n",
    "    print(stmnt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff2b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
